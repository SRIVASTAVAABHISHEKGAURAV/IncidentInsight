Thank you for contacting Microsoft LES Support. We will be looking into this Incident and update you further on this 
Update from MK:&nbsp; Showing offers&nbsp;@manoranjan.sahu&nbsp;CC:&nbsp;@[DTC]\DOC&nbsp;@[DTC]\LES NBA 
@Rahul Gottupulla&nbsp;@isitapatra&nbsp;hey folks, I took one of the events you pointed out (0022290146) as an example. I've checked and, indeed, the production is not present in LEFP package.  I took a look at the Orchestrator logs and, as per the EventMetadataSetup workflow for this event, this should have happened on November 27th&nbsp;    Then I've filtered the logs of that day for that production, and I found that the addition of the production to LEFP happened successfully, meaning that we got a 200-OK from TVP as you can see below (full logs here)   My understanding is that Orchestrator has done everything it should do successfully, so I'm guessing that either someone removed the production manually from LEFP, or some operation happened in the TVP side of things that ended up removing the production from there.  Please let me know if I can be of any further help. 
Adding @Rahul Nair, @Marco Backes, @Lorenzo Millani&nbsp;for context. You can take a look at my findings on the previous comment. 
Might be useful to have @Abhay Chaudhary&nbsp;take a look at this from TVP to see if the root cause can definitely be pointed there. Appears Orchestrator executed everything correctly regarding this event. 
@Rahul Nair&nbsp;, @Franco Zuccarelli&nbsp;, we noticed that for the events listed above there were DELETE calls to remove LEFP subscription on 11/28, 12/01 and 12/02. These were OSS calls from IP's listed below. Are these Orchestrator IP's ?&nbsp;Looking further there have been DELETE calls for other productions/servicecollections as well.&nbsp; I think there is change is encoder assignment for these events which is triggering these calls.&nbsp; Example: Event =&gt;&nbsp;0022290147Current service collection for this event is&nbsp;e0022290147e1000885. However, it had&nbsp;e0022290147e1000430 which got deleted on 12/01.&nbsp;     
hey&nbsp;@Abhay Chaudhary, thanks for the insights. Those API calls were made by orchestrator indeed, the reason being that the media was removed from the GMS Event, replaced by a media with a different id.For example, given the first row of your screenshot, the EventID is&nbsp;0022290143 and the media id was 1000431; and the currently existing production is&nbsp;e0022290143e1000885 (media id 1000885). This means that the media 1000431 was replaced by 1000885, and that explains why there is a DELETE operation for it.  On the same example above, I've checked the logs and the production&nbsp;e0022290143e1000885 was effectively added to LEFP, as you can see on the screenshot below (see complete logs here):  Just in case it's useful, the API call was a PUT HTTP request to&nbsp;https://appgw-boss.proda.nba.tv3cloud.com/oss/v1/subscriptions/LEFP/service-collections/e0022290143e1000885&nbsp;(you can find logs&nbsp;here) @Abhay Chaudhary&nbsp;is there any way for you to check if there was any API call made into TVP to remove production&nbsp;e0022290143e1000885&nbsp;from LEFP?cc&nbsp;@Rahul Nair&nbsp;@Marco Backes&nbsp;@Lorenzo Millani&nbsp;@Rahul Gottupulla&nbsp; 
@Franco Zuccarelli, I tried to find it out earlier. But unfortunately, with production level logging, I can't trace each request from Orchestrator like earlier. So, I was not able to find API calls related to&nbsp;e0022290143e1000885 from Orchestrator.&nbsp;&nbsp;  @manoranjan.sahu, can you please check if there is any other alternative to trace the request that Zuca mentioned?&nbsp;  &nbsp;@Rahul Nair&nbsp;@Marco Backes&nbsp;@Lorenzo Millani&nbsp;@Rahul Gottupulla&nbsp; 
@manoranjan.sahu, can you please check if there is any other alternative to trace the request that Zuca mentioned?&nbsp; CC: @Abhay Chaudhary&nbsp; 
Investigation is ongoing will keep you posted. 
Nothing further to add from MK. &nbsp;Suggest the ticket be closed.&nbsp; 
Basis latest sync up call with Mediakind, the issue is not reproducible as of now. So, they ave suggested to close this. In-case, team come across similar issue again, we can Re-open the incident. 
Seeing this again for the events&nbsp;0022290631,0022290660,0022290665 in the next one week, Reopening this.@Mayank Chhajed&nbsp;@Abhay Chaudhary&nbsp;@Ethan Folz&nbsp;@Rahul Nair&nbsp;@Franco Zuccarelli&nbsp;@abgaurav&nbsp;@Shaikh Hossain 
@Rahul Gottupulla&nbsp;@Franco Zuccarelli, can you please check sequence of OSS requests Orchestrator sent on UTC: Jan 19, 2023, 07:06 for event:&nbsp;0022290665?&nbsp;  Unfortunately, with production level logging, I am not able to see all the requests from Orchestrator for that event in Kibana. However, I noticed that PUT request for creation of event (ICID: b5b807157fc24a4190c69a1534810261) was at Jan 19, 2023 @ 07:06:15.000. However, there was another request (ICID:17c72fe5ee4c4b91a33742b68b4d821d) at&nbsp; Jan 19, 2023 @ 07:06:12.277&nbsp;for getting information of event&nbsp; which was responded with 404 as event wasn't created yet.&nbsp;&nbsp;  We will have to check internally with MediaFirst product team to analyze complete logs on the backend. In the meantime, can you please help confirm following?&nbsp; Timestamp you see on Orchestrator for these events and associated productions.&nbsp; Sequence of API's that were called (will be good to confirm that event/production were created before addition to LEFP package&nbsp;  @Mayank Chhajed&nbsp;, @Ethan Folz&nbsp;@Rahul Nair&nbsp;&nbsp;@abgaurav&nbsp;@Shaikh Hossain&nbsp;, @Steve Schwartz&nbsp;, @terry.neeley&nbsp;, @james.rupert&nbsp; 
Hey folks!&nbsp;@Abhay Chaudhary&nbsp;the logs that you see at the production level are correct: orchestrator first checks whether the event already exists or not, and then it creates or updates it in consequence. That's what you see a GET (that returns a 404) and after that, you see the PUT operation to create the queue.Regarding the addition of the productions to LEFP - I've taken production e0022290665e1000813 as the guinea pig. I've checked and the API call to add the production to LEFP was done after creating the production as you can see below. So, from an orchestration perspective, everything went well.&nbsp;  My understanding as per these findings is that, somehow, either the production was removed from LEFP by someone (not orchestrator), or TVP is returning 200 when attempting to add the production to the package but it doesn't work in the background.&nbsp;@Abhay Chaudhary&nbsp;does that make sense? Maybe it will be good to meet shortly and review logs together. Production creation:  Addition to LEFP: cc&nbsp;@Rahul Gottupulla&nbsp;@Mayank Chhajed&nbsp;@Ethan Folz&nbsp;@Rahul Nair&nbsp;@abgaurav&nbsp;@Shaikh Hossain&nbsp;@Steve Schwartz&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp; 
Thanks&nbsp;@Franco Zuccarelli&nbsp;. This is very helpful. Once we have similar data from our backend team, we can sync on this.&nbsp;&nbsp;  @Rahul Gottupulla&nbsp;@Mayank Chhajed&nbsp;@Ethan Folz&nbsp;@Rahul Nair&nbsp;@abgaurav&nbsp;@Shaikh Hossain&nbsp;@Steve Schwartz&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp;, @manoranjan.sahu&nbsp;, @Jeffery Truong&nbsp; 
@manoranjan.sahu&nbsp; Please update the status and link the internal SNOW / ADO ticket # for reference&nbsp; 
Latest update to be shared by @terry.neeley&nbsp;/ @Abhishek.Jain&nbsp;
@Neha Mishra&nbsp;SNOW ticket:&nbsp;INC0466228Internal ADO:&nbsp;https://dev.azure.com/mediakind/MediaFirst/_workitems/edit/1501187Fix applied on lower environment will push to prod environment soon.&nbsp;Will keep you postedFYI&nbsp;@terry.neeley&nbsp;
Correcting below comment statement:&nbsp;Fix not yet applied in lower environment too.&nbsp;Team is still investigation.&nbsp;We will keep you posted with latest updates.
Fix is still not applied to lower environment.We will keep you posted with latest updates.
Investigations still ongoing within MK, per @Abhishek Jain&nbsp;
We could not trace all the orchestrator requests necessary to find the root cause of&nbsp;the issue with the current logging level set to production. We created a RCS change request in MFTVP to increase the logging level to enable us further to debug next such occurrences. RCS is approved and is ready to be promoted in the environment with next deployment when planned.RCS -&nbsp;Pull request 114045: Enable Logging in NBA A,B,C - Repos (azure.com)cc: @Abhay Chaudhary&nbsp;@Franco Zuccarelli&nbsp;@Steve Schwartz&nbsp;@Mayank Chhajed&nbsp;@Abhishek Jain&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp;
Rahul,Per the notes below, we are unable to find any additional information for this incident -&nbsp; We are deploying an RCS in the future which will help but not with this specific incident.&nbsp; Not sure what we want to do with this&nbsp; &nbsp; Thoughts?@Kingshuk Ghosh&nbsp;@Abhay Chaudhary&nbsp;&nbsp;@Mayank Chhajed&nbsp;@Abhishek Jain&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp;@Rahul Nair&nbsp;&nbsp;
@Steve Schwartz&nbsp;@Kingshuk Ghosh&nbsp;@Abhay Chaudhary&nbsp;@Mayank Chhajed&nbsp;@Abhishek Jain&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp;- given that MK has created an RCS and this fix will be deployed in the near future. I am comfortable with closing this incident and reopening if needed. I have done so now. Thanks.
Seeing the same behavior again for the event&nbsp;Press Conference: Kings Postgame Presser (0022291650). Reingesting the game fixed the issue.@Abhishek.Jain&nbsp;to provide more details based on the new logs mentioned below.
@Rahul Gottupulla&nbsp;This RCS promotion is cancelled since PDU is anticipating performance degradation if log level increased. PDU is looking into other possibilities.
@Rahul Nair&nbsp;@Ethan Folz&nbsp;to suggest the next course of action.
As discussed during the incident review call, it was decided to put this incident on hold until MK's PDU team explores other possibilities to resolve the issue after their RCS promotion is canceled.&nbsp;
Today (on 4/17/2023), this issue was again observed for&nbsp;&nbsp;Shows: Nets RSN Pregame (0042290089)&nbsp;wherein there was &quot;no play options&quot; in MCD; and packager was missing :  Issue was fixed by re-ingesting the event. Also, please note that this&nbsp;RSN was not part of LEFP rather this was for League Pass.  CC: @[DTC]\DOC&nbsp;@[DTC]\LES NBA&nbsp;@Shailendra Singh Thakur&nbsp;@Abhishek.Jain&nbsp;@terry.neeley&nbsp;@james.rupert&nbsp;@Kingshuk Ghosh&nbsp; 
Seeing this for event&nbsp;0042290283. scheduled 05/02/2023
@Mayank Chhajed&nbsp;and @Rahul Nair&nbsp;to discuss&nbsp;  
Seeing the same for events 0042290386, 0042290401 scheduled 05/03/2023
Hi @Rahul Nair&nbsp;- following up from last week - were you able to gather logs for Abhay and team to review?
Assigning this to @Rahul Nair&nbsp;basis Sierra's comment until logs are shared with MK team 
Discussed last week - Since this issue is fixed with a re-ingest of games for now, the team agreed to review this in an upcoming sprint with a spike to determine and research a long-term fix. Updates to continue on this ticket once the work is ticketed and assigned to a sprint.&nbsp;cc @Hayden Lanham&nbsp;@Rahul Nair&nbsp;@Neha Mishra&nbsp;
@Sierra Ferrier&nbsp;@Rahul Nair&nbsp;@Neha Mishra&nbsp;@Sierra Ferrier&nbsp;added to Jira here:&nbsp;https://nba.atlassian.net/browse/MST-142
Marking this resolved as related jira ticket is created to find root cause and issue is not observed in the last month.